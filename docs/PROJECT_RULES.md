# LLM 기반 Apache NiFi 데이터플로우 자동 생성 시스템 - 프로젝트 규칙

## 1. 개발 규칙 (Development Rules)

### 1.1 코드 작성 규칙

#### 1.1.1 언어별 코딩 스타일
- **Python**: PEP 8 준수, Black 포매터 사용
- **JavaScript/TypeScript**: ESLint + Prettier 사용
- **Java**: Google Java Style Guide 준수
- **최대 라인 길이**: 120자
- **들여쓰기**: 4칸 (Python), 2칸 (JS/TS)

#### 1.1.2 네이밍 규칙
- **클래스명**: PascalCase (예: `DataFlowGenerator`)
- **함수/메서드명**: snake_case (Python), camelCase (JS/TS/Java)
- **상수명**: UPPER_SNAKE_CASE (예: `MAX_RETRY_COUNT`)
- **변수명**: snake_case (Python), camelCase (JS/TS/Java)
- **파일명**: snake_case.py, kebab-case.js

#### 1.1.3 주석 및 문서화
- **모든 public 함수/클래스**: docstring 필수
- **복잡한 로직**: 인라인 주석 추가
- **API 문서**: OpenAPI/Swagger 스펙 준수
- **README**: 각 모듈별 README.md 필수

### 1.2 아키텍처 규칙

#### 1.2.1 모듈 구조
```
src/
├── core/           # 핵심 비즈니스 로직
├── llm/           # LLM 관련 기능
├── nifi/          # NiFi 연동 기능
├── api/           # REST API 엔드포인트
└── utils/         # 공통 유틸리티
```

#### 1.2.2 의존성 관리
- **순환 의존성 금지**: 모듈 간 순환 참조 불허
- **계층별 의존성**: 상위 계층만 하위 계층 참조 가능
- **외부 라이브러리**: requirements.txt/package.json에 버전 명시

#### 1.2.3 설계 패턴
- **Factory Pattern**: 프로세서 생성
- **Strategy Pattern**: 다양한 LLM 모델 지원
- **Observer Pattern**: 플로우 상태 모니터링
- **Builder Pattern**: 복잡한 플로우 구성

## 2. LLM 통합 규칙 (LLM Integration Rules)

### 2.1 LLM 모델 선택 기준

#### 2.1.1 지원 모델
- **Primary**: OpenAI GPT-4, GPT-3.5-turbo
- **Secondary**: Anthropic Claude, Google Gemini
- **Local**: Ollama (Llama2, CodeLlama)
- **Enterprise**: Azure OpenAI, AWS Bedrock

#### 2.1.2 모델별 사용 용도
- **GPT-4**: 복잡한 플로우 생성, 최적화 제안
- **GPT-3.5-turbo**: 간단한 플로우 생성, 빠른 응답
- **CodeLlama**: 코드 생성 및 검증
- **Claude**: 긴 컨텍스트 처리

### 2.2 프롬프트 엔지니어링 규칙

#### 2.2.1 프롬프트 구조
```
[SYSTEM_CONTEXT]
[TASK_DESCRIPTION]
[INPUT_SPECIFICATION]
[OUTPUT_FORMAT]
[EXAMPLES]
[CONSTRAINTS]
```

#### 2.2.2 프롬프트 최적화
- **명확한 지시사항**: 모호한 표현 금지
- **예시 제공**: Few-shot learning 활용
- **제약사항 명시**: 출력 형식 및 제한사항 명확화
- **컨텍스트 관리**: 토큰 수 최적화

### 2.3 응답 처리 규칙

#### 2.3.1 응답 검증
- **JSON 형식 검증**: 스키마 기반 유효성 검사
- **NiFi 프로세서 존재 확인**: 실제 프로세서명 검증
- **연결 관계 검증**: 프로세서 간 연결 가능성 확인
- **보안 규칙 검증**: 민감 정보 노출 방지

#### 2.3.2 오류 처리
- **재시도 로직**: 최대 3회 재시도
- **Fallback 모델**: 주 모델 실패 시 대체 모델 사용
- **에러 로깅**: 상세한 에러 정보 기록
- **사용자 피드백**: 명확한 에러 메시지 제공

## 3. NiFi 통합 규칙 (NiFi Integration Rules)

### 3.1 프로세서 사용 규칙

#### 3.1.1 지원 프로세서 카테고리
- **Data Ingestion**: GetFile, GetHTTP, ConsumeKafka
- **Data Transformation**: JoltTransformJSON, ReplaceText, SplitText
- **Data Routing**: RouteOnAttribute, RouteOnContent
- **Data Output**: PutFile, PutHTTP, PublishKafka
- **Data Validation**: ValidateRecord, ValidateXml

#### 3.1.2 프로세서 선택 기준
- **성능**: 처리량 및 지연시간 고려
- **안정성**: 검증된 프로세서 우선 선택
- **유지보수성**: 설정 복잡도 최소화
- **확장성**: 스케일링 가능한 프로세서 선택

### 3.2 플로우 구성 규칙

#### 3.2.1 플로우 설계 원칙
- **단일 책임**: 각 프로세서는 하나의 기능만 수행
- **느슨한 결합**: 프로세서 간 의존성 최소화
- **높은 응집도**: 관련 기능은 그룹화
- **에러 처리**: 모든 경로에 에러 처리 로직 포함

#### 3.2.2 네이밍 규칙
- **프로세서 그룹**: `[Purpose]_[Environment]_[Version]`
- **프로세서명**: `[Action]_[Object]_[Sequence]`
- **연결명**: `[Source]_to_[Destination]`
- **속성명**: `[category].[property_name]`

### 3.3 보안 및 거버넌스 규칙

#### 3.3.1 보안 규칙
- **인증**: SSL/TLS 인증서 필수
- **권한 관리**: RBAC 기반 접근 제어
- **데이터 암호화**: 민감 데이터 암호화 필수
- **감사 로그**: 모든 작업 로그 기록

#### 3.3.2 데이터 거버넌스
- **데이터 분류**: 민감도별 데이터 분류
- **보존 정책**: 데이터 보존 기간 설정
- **접근 제어**: 데이터별 접근 권한 관리
- **변경 추적**: 데이터 변경 이력 관리

## 4. API 설계 규칙 (API Design Rules)

### 4.1 REST API 규칙

#### 4.1.1 URL 설계
- **RESTful**: HTTP 메서드 적절히 사용
- **명사 사용**: 동사 대신 명사로 리소스 표현
- **계층 구조**: 리소스 간 관계 명확히 표현
- **버전 관리**: `/api/v1/` 형태로 버전 명시

#### 4.1.2 응답 형식
```json
{
  "status": "success|error",
  "data": {},
  "message": "string",
  "timestamp": "ISO8601",
  "request_id": "uuid"
}
```

#### 4.1.3 HTTP 상태 코드
- **200**: 성공
- **201**: 생성 성공
- **400**: 잘못된 요청
- **401**: 인증 실패
- **403**: 권한 없음
- **404**: 리소스 없음
- **500**: 서버 오류

### 4.2 인증 및 권한 규칙

#### 4.2.1 인증 방식
- **JWT**: 토큰 기반 인증
- **OAuth 2.0**: 외부 서비스 연동
- **API Key**: 시스템 간 통신
- **세션**: 웹 UI 접근

#### 4.2.2 권한 레벨
- **Admin**: 모든 기능 접근
- **Developer**: 플로우 생성/수정
- **Viewer**: 읽기 전용 접근
- **System**: 시스템 간 통신

## 5. 테스트 규칙 (Testing Rules)

### 5.1 테스트 전략

#### 5.1.1 테스트 레벨
- **Unit Test**: 개별 함수/클래스 테스트
- **Integration Test**: 모듈 간 통합 테스트
- **System Test**: 전체 시스템 테스트
- **Performance Test**: 성능 및 부하 테스트

#### 5.1.2 테스트 커버리지
- **코드 커버리지**: 최소 80% 이상
- **브랜치 커버리지**: 최소 70% 이상
- **기능 커버리지**: 모든 주요 기능 테스트
- **에러 시나리오**: 예외 상황 테스트

### 5.2 테스트 자동화

#### 5.2.1 CI/CD 파이프라인
- **코드 품질 검사**: SonarQube 사용
- **자동 테스트**: GitHub Actions/Jenkins
- **배포 자동화**: Docker + Kubernetes
- **모니터링**: Prometheus + Grafana

#### 5.2.2 테스트 데이터
- **Mock 데이터**: 실제 데이터와 유사한 테스트 데이터
- **데이터 격리**: 테스트 환경별 데이터 분리
- **데이터 정리**: 테스트 후 데이터 정리
- **데이터 보안**: 민감 데이터 마스킹

## 6. 운영 규칙 (Operations Rules)

### 6.1 배포 규칙

#### 6.1.1 환경 관리
- **Development**: 개발 환경
- **Staging**: 스테이징 환경
- **Production**: 운영 환경
- **환경별 설정**: 환경 변수로 설정 관리

#### 6.1.2 배포 전략
- **Blue-Green**: 무중단 배포
- **Rolling Update**: 점진적 배포
- **Canary**: 카나리 배포
- **Rollback**: 빠른 롤백 지원

### 6.2 모니터링 및 로깅

#### 6.2.1 로그 레벨
- **ERROR**: 시스템 오류
- **WARN**: 경고 메시지
- **INFO**: 일반 정보
- **DEBUG**: 디버깅 정보

#### 6.2.2 메트릭 수집
- **시스템 메트릭**: CPU, 메모리, 디스크
- **애플리케이션 메트릭**: 응답시간, 처리량
- **비즈니스 메트릭**: 플로우 생성 수, 성공률
- **사용자 메트릭**: 활성 사용자, 세션 시간

### 6.3 장애 대응

#### 6.3.1 장애 분류
- **Critical**: 서비스 중단
- **High**: 주요 기능 장애
- **Medium**: 일부 기능 장애
- **Low**: 성능 저하

#### 6.3.2 대응 절차
1. **장애 감지**: 자동 모니터링
2. **초기 대응**: 즉시 대응팀 알림
3. **원인 분석**: 로그 및 메트릭 분석
4. **복구 작업**: 단계별 복구 진행
5. **사후 분석**: 재발 방지 대책 수립

## 7. 품질 관리 규칙 (Quality Management Rules)

### 7.1 코드 리뷰

#### 7.1.1 리뷰 기준
- **기능성**: 요구사항 충족 여부
- **성능**: 성능 최적화 여부
- **보안**: 보안 취약점 여부
- **유지보수성**: 코드 가독성 및 구조

#### 7.1.2 리뷰 프로세스
1. **Pull Request 생성**
2. **자동 테스트 실행**
3. **코드 리뷰 수행**
4. **피드백 반영**
5. **승인 후 병합**

### 7.2 문서화

#### 7.2.1 필수 문서
- **API 문서**: OpenAPI 스펙
- **사용자 가이드**: 기능별 사용법
- **개발자 가이드**: 개발 환경 설정
- **운영 가이드**: 배포 및 운영 방법

#### 7.2.2 문서 관리
- **버전 관리**: 코드와 문서 동기화
- **정기 업데이트**: 월 1회 문서 검토
- **접근성**: 모든 팀원 접근 가능
- **다국어 지원**: 한국어/영어 병행

## 8. 성능 최적화 규칙 (Performance Optimization Rules)

### 8.1 응답 시간 목표

#### 8.1.1 API 응답 시간
- **간단한 플로우 생성**: 5초 이내
- **복잡한 플로우 생성**: 30초 이내
- **플로우 조회**: 1초 이내
- **상태 확인**: 500ms 이내

#### 8.1.2 처리량 목표
- **동시 사용자**: 100명 이상
- **플로우 생성**: 시간당 1000개
- **API 호출**: 초당 100회
- **데이터 처리**: GB당 1분 이내

### 8.2 리소스 사용 최적화

#### 8.2.1 메모리 관리
- **메모리 누수 방지**: 정기적인 메모리 프로파일링
- **캐시 전략**: Redis 기반 캐싱
- **가비지 컬렉션**: JVM 튜닝
- **메모리 모니터링**: 실시간 메모리 사용량 추적

#### 8.2.2 CPU 최적화
- **비동기 처리**: 논블로킹 I/O 사용
- **병렬 처리**: 멀티스레딩 활용
- **알고리즘 최적화**: 시간 복잡도 개선
- **프로파일링**: 정기적인 성능 분석

이러한 규칙들을 통해 안정적이고 확장 가능한 LLM 기반 Apache NiFi 데이터플로우 자동 생성 시스템을 구축할 수 있습니다.
